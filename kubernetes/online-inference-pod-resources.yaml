apiVersion: v1
kind: Pod
metadata:
  name: online-inference-v1
spec:
  containers:
  - name: online-inference-v1
    image: ilyasssklimov/online_inference:v1
    ports:
    - containerPort: 8000
    resources:
      requests:
        memory: "1Gi"
        cpu: "500m"
      limits:
        memory: "2Gi"
        cpu: "1000m"

