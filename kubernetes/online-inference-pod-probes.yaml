apiVersion: v1
kind: Pod
metadata:
  name: online-inference-v2
spec:
  containers:
  - name: online-inference-v2
    image: ilyasssklimov/online_inference:v2
    ports:
    - containerPort: 8000
    resources:
      requests:
        memory: "1Gi"
        cpu: "500m"
      limits:
        memory: "2Gi"
        cpu: "1000m"
    livenessProbe:
      httpGet:
        path: /
        port: 8000
      initialDelaySeconds: 20
      periodSeconds: 10
    readinessProbe:
      httpGet:
        path: /
        port: 8000
      initialDelaySeconds: 20
      periodSeconds: 10